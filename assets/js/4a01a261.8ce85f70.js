"use strict";(self.webpackChunkgsf_docusaurus_template=self.webpackChunkgsf_docusaurus_template||[]).push([[5497],{4137:(e,r,t)=>{t.d(r,{Zo:()=>u,kt:()=>m});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=n.createContext({}),c=function(e){var r=n.useContext(l),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},u=function(e){var r=c(e.components);return n.createElement(l.Provider,{value:r},e.children)},p={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},d=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=c(t),m=a,f=d["".concat(l,".").concat(m)]||d[m]||p[m]||i;return t?n.createElement(f,o(o({ref:r},u),{},{components:t})):n.createElement(f,o({ref:r},u))}));function m(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=d;var s={};for(var l in r)hasOwnProperty.call(r,l)&&(s[l]=r[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var c=2;c<i;c++)o[c]=t[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},9394:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var n=t(7462),a=(t(7294),t(4137));const i={version:1,submitted_by:"navveenb",published_date:"tbd",category:"ai",tags:["ai","machine-learning","serverless","role:data-scientist","size:small"]},o="Adopt serverless architecture for ML workload process",s={unversionedId:"catalog/ai/serverless-model-development",id:"catalog/ai/serverless-model-development",title:"Adopt serverless architecture for ML workload process",description:"Description",source:"@site/docs/catalog/ai/serverless-model-development.md",sourceDirName:"catalog/ai",slug:"/catalog/ai/serverless-model-development",permalink:"/catalog/ai/serverless-model-development",draft:!1,editUrl:"https://github.com/Green-Software-Foundation/green-software-patterns/docs/catalog/ai/serverless-model-development.md",tags:[{label:"ai",permalink:"/tags/ai"},{label:"machine-learning",permalink:"/tags/machine-learning"},{label:"serverless",permalink:"/tags/serverless"},{label:"role:data-scientist",permalink:"/tags/role-data-scientist"},{label:"size:small",permalink:"/tags/size-small"}],version:"current",frontMatter:{version:1,submitted_by:"navveenb",published_date:"tbd",category:"ai",tags:["ai","machine-learning","serverless","role:data-scientist","size:small"]},sidebar:"tutorialSidebar",previous:{title:"Select the right hardware/VM instance types for training and inference of AI/ML process",permalink:"/catalog/ai/right-hardware-type"},next:{title:"Cloud",permalink:"/catalog/cloud/"}},l={},c=[{value:"Description",id:"description",level:2},{value:"Solution",id:"solution",level:2},{value:"SCI Impact",id:"sci-impact",level:2},{value:"Assumptions",id:"assumptions",level:2},{value:"Considerations",id:"considerations",level:2},{value:"References",id:"references",level:2}],u={toc:c};function p(e){let{components:r,...t}=e;return(0,a.kt)("wrapper",(0,n.Z)({},u,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"adopt-serverless-architecture-for-ml-workload-process"},"Adopt serverless architecture for ML workload process"),(0,a.kt)("h2",{id:"description"},"Description"),(0,a.kt)("p",null,"Building an ML model requires a series of steps, like building\na data pipeline for data capture, data cleansing, feature generation, and running multiple training iterations and experiments to get the desired accuracy. All of these steps take significant computing resources that need to be optimized for efficient utilization."),(0,a.kt)("h2",{id:"solution"},"Solution"),(0,a.kt)("p",null,"Adopt a serverless architecture for maximum resource utilization for your entire AI/ML model development process like data pipeline, training and experiments. Serverless ensures the resources are launched only when required. "),(0,a.kt)("h2",{id:"sci-impact"},"SCI Impact"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"SCI = (E * I) + M per R"),"\n",(0,a.kt)("a",{parentName:"p",href:"https://grnsft.org/sci"},"Software Carbon Intensity Spec")),(0,a.kt)("p",null,"For the SCI equation, adopting serverless architecture for AI/ML workload process would impact the following:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"'E':  Having a serverless architecture for the AI/ML development process provides efficient resource utilization and reduces the energy consumption of the compute resources and consequently, the E number should decrease."),(0,a.kt)("li",{parentName:"ul"},"'M':  Having a serverless architecture for the AI/ML development process would lead to effective resource hardware/resource utilization as the resources would be provisioned only when required and consequently, the M number should decrease.")),(0,a.kt)("h2",{id:"assumptions"},"Assumptions"),(0,a.kt)("p",null,"None"),(0,a.kt)("h2",{id:"considerations"},"Considerations"),(0,a.kt)("p",null,"Evaluate and consider what AI/ML workloads can be moved to serverless. Consider if your application can afford cold start during serverless resource initialization. "),(0,a.kt)("h2",{id:"references"},"References"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://cloud.google.com/blog/products/ai-machine-learning/serverless-machine-learning-pipelines-on-google-cloud"},"Serverless Pipeline on Google Cloud")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://aws.amazon.com/blogs/machine-learning/machine-learning-inference-at-scale-using-aws-serverless/"},"Machine learning inference at scale using AWS serverless"))))}p.isMDXComponent=!0}}]);