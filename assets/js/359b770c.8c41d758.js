"use strict";(self.webpackChunkgsf_docusaurus_template=self.webpackChunkgsf_docusaurus_template||[]).push([[5677],{4137:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=c(n),m=r,b=p["".concat(l,".").concat(m)]||p[m]||u[m]||o;return n?a.createElement(b,s(s({ref:t},d),{},{components:n})):a.createElement(b,s({ref:t},d))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=p;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,s[1]=i;for(var c=2;c<o;c++)s[c]=n[c];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},1490:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var a=n(7462),r=(n(7294),n(4137));const o={version:1,submitted_by:"yelghali",published_date:new Date("2022-11-10T00:00:00.000Z"),category:"cloud",description:"By default, Kubernetes scales workloads based on CPU and RAM utilization. In practice, however, it's difficult to correlate your application's demand drivers with CPU and RAM utilization. Scaling your workload based on relevant demand metrics that drive scaling of your applications, such as HTTP requests, queue length, and cloud alerting events can help reduce resource utilization, and therefore also your carbon emissions.",tags:["cloud","serverless","kubernetes","role:software-engineer","role:cloud-engineer","size:medium"]},s="Scale Kubernetes workloads based on relevant demand metrics",i={unversionedId:"catalog/cloud/scale-kubernetes-workloads-based-on-events",id:"catalog/cloud/scale-kubernetes-workloads-based-on-events",title:"Scale Kubernetes workloads based on relevant demand metrics",description:"By default, Kubernetes scales workloads based on CPU and RAM utilization. In practice, however, it's difficult to correlate your application's demand drivers with CPU and RAM utilization. Scaling your workload based on relevant demand metrics that drive scaling of your applications, such as HTTP requests, queue length, and cloud alerting events can help reduce resource utilization, and therefore also your carbon emissions.",source:"@site/docs/catalog/cloud/scale-kubernetes-workloads-based-on-events.md",sourceDirName:"catalog/cloud",slug:"/catalog/cloud/scale-kubernetes-workloads-based-on-events",permalink:"/catalog/cloud/scale-kubernetes-workloads-based-on-events",draft:!1,editUrl:"https://github.com/Green-Software-Foundation/patterns/edit/main/docs/catalog/cloud/scale-kubernetes-workloads-based-on-events.md",tags:[{label:"cloud",permalink:"/tags/cloud"},{label:"serverless",permalink:"/tags/serverless"},{label:"kubernetes",permalink:"/tags/kubernetes"},{label:"role:software-engineer",permalink:"/tags/role-software-engineer"},{label:"role:cloud-engineer",permalink:"/tags/role-cloud-engineer"},{label:"size:medium",permalink:"/tags/size-medium"}],version:"current",frontMatter:{version:1,submitted_by:"yelghali",published_date:"2022-11-10T00:00:00.000Z",category:"cloud",description:"By default, Kubernetes scales workloads based on CPU and RAM utilization. In practice, however, it's difficult to correlate your application's demand drivers with CPU and RAM utilization. Scaling your workload based on relevant demand metrics that drive scaling of your applications, such as HTTP requests, queue length, and cloud alerting events can help reduce resource utilization, and therefore also your carbon emissions.",tags:["cloud","serverless","kubernetes","role:software-engineer","role:cloud-engineer","size:medium"]},sidebar:"tutorialSidebar",previous:{title:"Scale infrastructure with user load",permalink:"/catalog/cloud/scale-infrastructure-with-user-load"},next:{title:"Scale logical components independently",permalink:"/catalog/cloud/scale-logical-components-independently"}},l={},c=[{value:"Description",id:"description",level:2},{value:"Solution",id:"solution",level:2},{value:"SCI Impact",id:"sci-impact",level:2},{value:"Assumptions",id:"assumptions",level:2},{value:"Considerations",id:"considerations",level:2}],d={toc:c};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"scale-kubernetes-workloads-based-on-relevant-demand-metrics"},"Scale Kubernetes workloads based on relevant demand metrics"),(0,r.kt)("h2",{id:"description"},"Description"),(0,r.kt)("p",null,"By default, Kubernetes scales workloads based on CPU and RAM utilization. In practice, however, it's difficult to correlate your application's demand drivers with CPU and RAM utilization."),(0,r.kt)("p",null,"Scaling your workload based on relevant demand metrics that drive scaling of your applications, such as HTTP requests, queue length, and cloud alerting events can help reduce resource utilization, and therefore also your carbon emissions."),(0,r.kt)("h2",{id:"solution"},"Solution"),(0,r.kt)("p",null,"Implement a custom scaler for your application, or use ",(0,r.kt)("a",{parentName:"p",href:"https://keda.sh"},"KEDA")," to help you build event-driven Kubernetes applications, to allow scaling down to zero when there is no demand."),(0,r.kt)("p",null,"In addition to scaling Kubernetes applications based on relevent scaling metrics (or events), cluster auto-scaling and bursting capabilities are also used to scale infrastructure based on demand."),(0,r.kt)("h2",{id:"sci-impact"},"SCI Impact"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"SCI = (E * I) + M per R"),"\n",(0,r.kt)("a",{parentName:"p",href:"https://grnsft.org/sci"},"Software Carbon Intensity Spec")),(0,r.kt)("p",null,"Scaling based on events will impact SCI as follows:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"M"),": By scaling the workloads based on demand and reducing resource utilization, the total embodied carbon emissions by the Kubernetes cluster is lower.")),(0,r.kt)("h2",{id:"assumptions"},"Assumptions"),(0,r.kt)("p",null,"The metrics that drive application demand and scaling needs are known."),(0,r.kt)("h2",{id:"considerations"},"Considerations"),(0,r.kt)("p",null,"If your workloads have predictable usage patterns, you could implement scaling based on time as an alternative to optimize utilization and reduce carbon emissions."))}u.isMDXComponent=!0}}]);